{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import openai\n",
    "\n",
    "from src.eval import extract_diagnosis_name\n",
    "from src.utils import call_gpt3_api, call_gpt4_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API credentials\n",
    "openai_key = open(\"../keys/openai_key.txt\", \"r\")\n",
    "openai.api_key = openai_key.readlines()[0]\n",
    "\n",
    "organization_id = open(\"../keys/rajpurkarlab_org_id.txt\", \"r\")\n",
    "openai.organization = organization_id.readlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_cases = [\"public_case0\"+str(x) for x in range(1,10)] + [\"public_case\"+str(x) for x in range(10,101)]\n",
    "private_cases = [\"private_case0\"+str(x) for x in range(1,10)] + [\"private_case\"+str(x) for x in range(10,41)]\n",
    "all_cases = public_cases + private_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3.5 conversation with PE\n",
    "diagnosis_dialogues = []\n",
    "res = json.load(open(\"./results/conversations_raw/conversations_gpt3.json\",\"r\"))\n",
    "for case in all_cases:\n",
    "    for j in range(10):\n",
    "        temp = res[case][f\"trial_{j}_doctor_responses_with_exam\"]\n",
    "        flag=1\n",
    "        for k in range(len(temp)):\n",
    "            if temp[k][\"role\"]==\"assistant\":\n",
    "                if \"final \" in temp[k][\"content\"].lower():\n",
    "                    diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                    flag=0\n",
    "                    break\n",
    "                elif \"?\" not in temp[k][\"content\"].lower():\n",
    "                    if \"based on \" in temp[k][\"content\"].lower():\n",
    "                        diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                        flag=0\n",
    "                        break\n",
    "        if flag==1:\n",
    "            diagnosis_dialogues.append(temp[-1][\"content\"])\n",
    "            \n",
    "extracted_diagnoses = []\n",
    "for x in tqdm(diagnosis_dialogues):\n",
    "    extracted_diagnoses.append(extract_diagnosis_name(x, \"gpt-3.5\"))\n",
    "    \n",
    "pd.DataFrame(np.array(extracted_diagnoses).reshape(len(all_cases),10)).T.to_csv(\"./results/extracted_diagnoses_withPE_gpt3.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e8e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3.5 conversation without PE\n",
    "diagnosis_dialogues = []\n",
    "res = json.load(open(\"./results/conversations_raw/conversations_gpt3.json\",\"r\"))\n",
    "for case in all_cases:\n",
    "    for j in range(10):\n",
    "        temp = res[case][f\"trial_{j}_doctor_responses\"]\n",
    "        flag=1\n",
    "        for k in range(len(temp)):\n",
    "            if temp[k][\"role\"]==\"assistant\":\n",
    "                if \"final \" in temp[k][\"content\"].lower():\n",
    "                    diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                    flag=0\n",
    "                    break\n",
    "                elif \"?\" not in temp[k][\"content\"].lower():\n",
    "                    if \"based on \" in temp[k][\"content\"].lower():\n",
    "                        diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                        flag=0\n",
    "                        break\n",
    "        if flag==1:\n",
    "            diagnosis_dialogues.append(temp[-1][\"content\"])\n",
    "            \n",
    "extracted_diagnoses = []\n",
    "for x in tqdm(diagnosis_dialogues):\n",
    "    extracted_diagnoses.append(extract_diagnosis_name(x, \"gpt-3.5\"))\n",
    "    \n",
    "pd.DataFrame(np.array(extracted_diagnoses).reshape(len(all_cases),10)).T.to_csv(\"./results/extracted_diagnoses_withoutPE_gpt3.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872342f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 conversation with PE\n",
    "diagnosis_dialogues = []\n",
    "res = json.load(open(\"./results/conversations_raw/conversations_gpt4.json\",\"r\"))\n",
    "for case in all_cases:\n",
    "    for j in range(10):\n",
    "        temp = res[case][f\"trial_{j}_doctor_responses_with_exam\"]\n",
    "        flag=1\n",
    "        for k in range(len(temp)):\n",
    "            if temp[k][\"role\"]==\"assistant\":\n",
    "                if \"final \" in temp[k][\"content\"].lower():\n",
    "                    diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                    flag=0\n",
    "                    break\n",
    "                elif \"?\" not in temp[k][\"content\"].lower():\n",
    "                    if \"based on \" in temp[k][\"content\"].lower():\n",
    "                        diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                        flag=0\n",
    "                        break\n",
    "        if flag==1:\n",
    "            diagnosis_dialogues.append(temp[-1][\"content\"])\n",
    "\n",
    "extracted_diagnoses = []\n",
    "for x in tqdm(diagnosis_dialogues):\n",
    "    extracted_diagnoses.append(extract_diagnosis_name(x, \"gpt-3.5\"))\n",
    "    \n",
    "pd.DataFrame(np.array(extracted_diagnoses).reshape(len(all_cases),10)).T.to_csv(\"./results/extracted_diagnoses_withPE_gpt4.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecdfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 conversation without PE\n",
    "diagnosis_dialogues = []\n",
    "res = json.load(open(\"./results/conversations_raw/conversations_gpt4.json\",\"r\"))\n",
    "for case in all_cases:\n",
    "    for j in range(10):\n",
    "        temp = res[case][f\"trial_{j}_doctor_responses\"]\n",
    "        flag=1\n",
    "        for k in range(len(temp)):\n",
    "            if temp[k][\"role\"]==\"assistant\":\n",
    "                if \"final \" in temp[k][\"content\"].lower():\n",
    "                    diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                    flag=0\n",
    "                    break\n",
    "                elif \"?\" not in temp[k][\"content\"].lower():\n",
    "                    if \"based on \" in temp[k][\"content\"].lower():\n",
    "                        diagnosis_dialogues.append(temp[k][\"content\"])\n",
    "                        flag=0\n",
    "                        break\n",
    "        if flag==1:\n",
    "            diagnosis_dialogues.append(temp[-1][\"content\"])\n",
    "\n",
    "extracted_diagnoses = []\n",
    "for x in tqdm(diagnosis_dialogues):\n",
    "    extracted_diagnoses.append(extract_diagnosis_name(x, \"gpt-3.5\"))\n",
    "    \n",
    "pd.DataFrame(np.array(extracted_diagnoses).reshape(len(all_cases),10)).T.to_csv(\"./results/extracted_diagnoses_withoutPE_gpt4.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f808a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133a0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
