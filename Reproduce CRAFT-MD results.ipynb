{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0b405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524eac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "deployment_name = \"gpt-4\"\n",
    "openai.api_base = \"https://codesidebias.openai.azure.com/openai/deployments/gpt-4/chat/completions?api-version=2024-08-01-preview\"\n",
    "openai.api_key = \"766aeef6717d4c09b997c943f75ce7d5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483c4570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/healthy-ml/scratch/abinitha/miniconda3/envs/detect/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from src.utils import get_choices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad83ae",
   "metadata": {},
   "source": [
    "## Generate clinical LLM agent responses for vignette and conversational formats (multi-turn, single-turn and summarized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01667361",
   "metadata": {},
   "source": [
    "### OpenAI Models (GPT-3.5, GPT-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a24582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.craftmd import craftmd_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae0412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "model_name = \"gpt4_1106\"\n",
    "dataset = pd.read_csv(\"/data/healthy-ml/scratch/abinitha/craft-md/craft-md/data_augmented/baseline.csv\", index_col=0)\n",
    "\n",
    "cases = [(dataset.loc[idx,\"case_id\"], \n",
    "          dataset.loc[idx,\"case_vignette\"], \n",
    "          dataset.loc[idx,\"category\"],\n",
    "          get_choices(dataset,idx)) for idx in dataset.index]\n",
    "\n",
    "path_dir = f\"results/{model_name}\"\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    case = cases[i]\n",
    "    craftmd_gpt(case, path_dir, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2206c",
   "metadata": {},
   "source": [
    "### Open-source Models (Mistral-v1, Mistral-v2, LLaMA2-7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b549c",
   "metadata": {},
   "source": [
    "These models require GPU resources. We performed all evaluations on Quadro RTX 8000 48gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92aea9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.craftmd import craftmd_opensource\n",
    "from src.models import get_model_and_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45e9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To download open-source models, if not already installed in your conda environment\n",
    "# from huggingface_hub import login\n",
    "# login(token = \"insert_huggingface_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a995f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistral-v2\"\n",
    "dataset = pd.read_csv(\"data/usmle_and_derm_dataset.csv\", index_col=0)\n",
    "\n",
    "cases = [(dataset.loc[idx,\"case_id\"], \n",
    "          dataset.loc[idx,\"case_vignette\"], \n",
    "          dataset.loc[idx,\"category\"],\n",
    "          get_choices(dataset,idx)) for idx in dataset.index]\n",
    "\n",
    "path_dir = f\"results/{model_name}\"\n",
    "\n",
    "case = cases[0]\n",
    "\n",
    "model, tokenizer = get_model_and_tokenizer(model_name)\n",
    "\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id \n",
    "\n",
    "craftmd_opensource(case, path_dir, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8f4d1",
   "metadata": {},
   "source": [
    "### Multimodal LLM (GPT-4V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a820ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.craftmd import craftmd_multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2147dc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'craftmd_multimodal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m path_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m img_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../craft-md-v2/data/nejm/imgs/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcraftmd_multimodal\u001b[49m(cases[\u001b[38;5;241m0\u001b[39m], img_dir, path_dir, deployment_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'craftmd_multimodal' is not defined"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt4v\"\n",
    "dataset = pd.read_csv(\"data/nejmai_dataset.csv\", index_col=0)\n",
    "\n",
    "cases = [(dataset.loc[idx,\"case_id\"],\n",
    "          dataset.loc[idx,\"case_vignette\"],\n",
    "          get_choices(dataset,idx)) for idx in dataset.index]\n",
    "\n",
    "path_dir = f\"./results/{model_name}\"\n",
    "img_dir = f\"../../craft-md-v2/data/nejm/imgs/\"\n",
    "\n",
    "craftmd_multimodal(cases[0], img_dir, path_dir, deployment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866c7b7e",
   "metadata": {},
   "source": [
    "# Evaluate using Grader-AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebde4a6",
   "metadata": {},
   "source": [
    "Below code works for both open-source and GPT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5acc40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/healthy-ml/scratch/abinitha/miniconda3/envs/detect/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from src.graderai_eval import graderai_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc2022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread for case_10 is dispatched.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"gpt4_1106\"\n",
    "dataset = pd.read_csv(\"data_augmented/baseline.csv\", index_col=0)\n",
    "\n",
    "experiment_names = [\"vignette_frq\", \"multiturn_frq\", \"singleturn_frq\", \"summarized_frq\"]\n",
    "path_dir = f\"/data/healthy-ml/scratch/abinitha/craft-md/craft-md/results/gpt4_1106/lowercase\"\n",
    "\n",
    "graderai_evaluation(\"case_10\", dataset, path_dir, experiment_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa96855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['case_vignette', 'question', 'trial_0', 'trial_1', 'trial_2', 'trial_3', 'trial_4', 'correct_ans']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"results/gpt4_1106/baseline/case_2.json\"  # Replace with your actual file path\n",
    "\n",
    "# Read the JSON file\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)  # Load JSON into a dictionary\n",
    "\n",
    "# Get the list of keys\n",
    "keys_list = list(data.keys())\n",
    "\n",
    "# Print the keys\n",
    "print(keys_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0e1b2",
   "metadata": {},
   "source": [
    "# Evals Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5f24ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'evaluation_vignette_frq': 711.0, 'evaluation_multiturn_frq': 433.0, 'evaluation_singleturn_frq': 295.0, 'evaluation_summarized_frq': 400.0}\n",
      "792\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def sum_nested_dict(d, sum_dict):\n",
    "    \"\"\"Recursively sums numeric values from nested dictionaries.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        if isinstance(value, (int, float)):  # If value is numeric, sum it\n",
    "            sum_dict[key] += value\n",
    "        elif isinstance(value, dict):  # If value is a nested dictionary, recurse\n",
    "            sum_nested_dict(value, sum_dict)\n",
    "\n",
    "folder_path = Path(\"results/gpt4_1106/lowercase\")  # Replace with actual folder path\n",
    "count = 0\n",
    "sum_dict = defaultdict(float)  # Stores the sum of each key\n",
    "\n",
    "# Iterate over JSON files in the folder\n",
    "for file_path in sorted(folder_path.glob(\"*.json\")):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        count = count + 1\n",
    "        data = json.load(f)  # Load JSON into a dictionary\n",
    "\n",
    "    # Recursively sum values\n",
    "    sum_nested_dict(data, sum_dict)\n",
    "\n",
    "# Print the total sum for each key\n",
    "print(dict(sum_dict))\n",
    "print(count * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3348dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(\"your_folder_path\")  # Replace with the actual folder path\n",
    "key_to_extract = \"your_key\"  # Replace with the key you want to extract\n",
    "\n",
    "# Iterate over JSON files in the folder\n",
    "for file_path in sorted(folder_path.glob(\"*.json\")):  # Sort ensures consistent order\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)  # Load JSON file into dictionary\n",
    "    \n",
    "    # Extract and print the value for the specific key\n",
    "    if key_to_extract in data:\n",
    "        print(f\"{file_path.name}: {data[key_to_extract]}\")\n",
    "    else:\n",
    "        print(f\"{file_path.name}: Key '{key_to_extract}' not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9f37d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: case_1.json\n",
      "Processed: case_10.json\n",
      "Processed: case_100.json\n",
      "Processed: case_101.json\n",
      "Processed: case_102.json\n",
      "Processed: case_103.json\n",
      "Processed: case_104.json\n",
      "Processed: case_106.json\n",
      "Processed: case_107.json\n",
      "Processed: case_109.json\n",
      "Processed: case_11.json\n",
      "Processed: case_112.json\n",
      "Processed: case_113.json\n",
      "Processed: case_115.json\n",
      "Processed: case_117.json\n",
      "Processed: case_118.json\n",
      "Processed: case_119.json\n",
      "Processed: case_12.json\n",
      "Processed: case_121.json\n",
      "Processed: case_123.json\n",
      "Processed: case_124.json\n",
      "Processed: case_126.json\n",
      "Processed: case_127.json\n",
      "Processed: case_128.json\n",
      "Processed: case_13.json\n",
      "Processed: case_131.json\n",
      "Processed: case_132.json\n",
      "Processed: case_134.json\n",
      "Processed: case_135.json\n",
      "Processed: case_137.json\n",
      "Processed: case_139.json\n",
      "Processed: case_14.json\n",
      "Processed: case_140.json\n",
      "Processed: case_141.json\n",
      "Processed: case_143.json\n",
      "Processed: case_144.json\n",
      "Processed: case_145.json\n",
      "Processed: case_146.json\n",
      "Processed: case_147.json\n",
      "Processed: case_148.json\n",
      "Processed: case_149.json\n",
      "Processed: case_150.json\n",
      "Processed: case_151.json\n",
      "Processed: case_152.json\n",
      "Processed: case_155.json\n",
      "Processed: case_156.json\n",
      "Processed: case_158.json\n",
      "Processed: case_16.json\n",
      "Processed: case_161.json\n",
      "Processed: case_162.json\n",
      "Processed: case_163.json\n",
      "Processed: case_164.json\n",
      "Processed: case_165.json\n",
      "Processed: case_167.json\n",
      "Processed: case_168.json\n",
      "Processed: case_17.json\n",
      "Processed: case_170.json\n",
      "Processed: case_171.json\n",
      "Processed: case_174.json\n",
      "Processed: case_177.json\n",
      "Processed: case_180.json\n",
      "Processed: case_181.json\n",
      "Processed: case_182.json\n",
      "Processed: case_186.json\n",
      "Processed: case_187.json\n",
      "Processed: case_188.json\n",
      "Processed: case_189.json\n",
      "Processed: case_19.json\n",
      "Processed: case_190.json\n",
      "Processed: case_191.json\n",
      "Processed: case_195.json\n",
      "Processed: case_196.json\n",
      "Processed: case_197.json\n",
      "Processed: case_198.json\n",
      "Processed: case_199.json\n",
      "Processed: case_2.json\n",
      "Processed: case_20.json\n",
      "Processed: case_200.json\n",
      "Processed: case_203.json\n",
      "Processed: case_205.json\n",
      "Processed: case_206.json\n",
      "Processed: case_208.json\n",
      "Processed: case_21.json\n",
      "Processed: case_210.json\n",
      "Processed: case_211.json\n",
      "Processed: case_212.json\n",
      "Processed: case_213.json\n",
      "Processed: case_215.json\n",
      "Processed: case_22.json\n",
      "Processed: case_223.json\n",
      "Processed: case_229.json\n",
      "Processed: case_230.json\n",
      "Processed: case_232.json\n",
      "Processed: case_236.json\n",
      "Processed: case_238.json\n",
      "Processed: case_24.json\n",
      "Processed: case_240.json\n",
      "Processed: case_25.json\n",
      "Processed: case_250.json\n",
      "Processed: case_251.json\n",
      "Processed: case_252.json\n",
      "Processed: case_254.json\n",
      "Processed: case_257.json\n",
      "Processed: case_258.json\n",
      "Processed: case_26.json\n",
      "Processed: case_267.json\n",
      "Processed: case_268.json\n",
      "Processed: case_270.json\n",
      "Processed: case_271.json\n",
      "Processed: case_273.json\n",
      "Processed: case_274.json\n",
      "Processed: case_276.json\n",
      "Processed: case_29.json\n",
      "Processed: case_293.json\n",
      "Processed: case_297.json\n",
      "Processed: case_298.json\n",
      "Processed: case_3.json\n",
      "Processed: case_30.json\n",
      "Processed: case_300.json\n",
      "Processed: case_301.json\n",
      "Processed: case_307.json\n",
      "Processed: case_308.json\n",
      "Processed: case_314.json\n",
      "Processed: case_317.json\n",
      "Processed: case_326.json\n",
      "Processed: case_33.json\n",
      "Processed: case_332.json\n",
      "Processed: case_336.json\n",
      "Processed: case_341.json\n",
      "Processed: case_344.json\n",
      "Processed: case_345.json\n",
      "Processed: case_346.json\n",
      "Processed: case_349.json\n",
      "Processed: case_35.json\n",
      "Processed: case_351.json\n",
      "Processed: case_352.json\n",
      "Processed: case_353.json\n",
      "Processed: case_355.json\n",
      "Processed: case_359.json\n",
      "Processed: case_36.json\n",
      "Processed: case_360.json\n",
      "Processed: case_363.json\n",
      "Processed: case_367.json\n",
      "Processed: case_37.json\n",
      "Processed: case_374.json\n",
      "Processed: case_375.json\n",
      "Processed: case_376.json\n",
      "Processed: case_381.json\n",
      "Processed: case_384.json\n",
      "Processed: case_385.json\n",
      "Processed: case_386.json\n",
      "Processed: case_388.json\n",
      "Processed: case_394.json\n",
      "Processed: case_4.json\n",
      "Processed: case_40.json\n",
      "Processed: case_403.json\n",
      "Processed: case_41.json\n",
      "Processed: case_410.json\n",
      "Processed: case_411.json\n",
      "Processed: case_415.json\n",
      "Processed: case_417.json\n",
      "Processed: case_418.json\n",
      "Processed: case_419.json\n",
      "Processed: case_42.json\n",
      "Processed: case_423.json\n",
      "Processed: case_424.json\n",
      "Processed: case_425.json\n",
      "Processed: case_426.json\n",
      "Processed: case_43.json\n",
      "Processed: case_433.json\n",
      "Processed: case_436.json\n",
      "Processed: case_44.json\n",
      "Processed: case_441.json\n",
      "Processed: case_442.json\n",
      "Processed: case_443.json\n",
      "Processed: case_445.json\n",
      "Processed: case_447.json\n",
      "Processed: case_449.json\n",
      "Processed: case_450.json\n",
      "Processed: case_451.json\n",
      "Processed: case_454.json\n",
      "Processed: case_457.json\n",
      "Processed: case_458.json\n",
      "Processed: case_46.json\n",
      "Processed: case_461.json\n",
      "Processed: case_462.json\n",
      "Processed: case_468.json\n",
      "Processed: case_47.json\n",
      "Processed: case_471.json\n",
      "Processed: case_472.json\n",
      "Processed: case_474.json\n",
      "Processed: case_48.json\n",
      "Processed: case_480.json\n",
      "Processed: case_482.json\n",
      "Processed: case_483.json\n",
      "Processed: case_492.json\n",
      "Processed: case_493.json\n",
      "Processed: case_495.json\n",
      "Processed: case_5.json\n",
      "Processed: case_506.json\n",
      "Processed: case_51.json\n",
      "Processed: case_514.json\n",
      "Processed: case_517.json\n",
      "Processed: case_52.json\n",
      "Processed: case_521.json\n",
      "Processed: case_523.json\n",
      "Processed: case_524.json\n",
      "Processed: case_525.json\n",
      "Processed: case_529.json\n",
      "Processed: case_53.json\n",
      "Processed: case_534.json\n",
      "Processed: case_536.json\n",
      "Processed: case_538.json\n",
      "Processed: case_540.json\n",
      "Processed: case_541.json\n",
      "Processed: case_544.json\n",
      "Processed: case_546.json\n",
      "Processed: case_55.json\n",
      "Processed: case_58.json\n",
      "Processed: case_6.json\n",
      "Processed: case_60.json\n",
      "Processed: case_61.json\n",
      "Processed: case_62.json\n",
      "Processed: case_64.json\n",
      "Processed: case_65.json\n",
      "Processed: case_66.json\n",
      "Processed: case_67.json\n",
      "Processed: case_7.json\n",
      "Processed: case_72.json\n",
      "Processed: case_73.json\n",
      "Processed: case_75.json\n",
      "Processed: case_77.json\n",
      "Processed: case_78.json\n",
      "Processed: case_8.json\n",
      "Processed: case_80.json\n",
      "Processed: case_81.json\n",
      "Processed: case_82.json\n",
      "Processed: case_83.json\n",
      "Processed: case_85.json\n",
      "Processed: case_86.json\n",
      "Processed: case_87.json\n",
      "Processed: case_89.json\n",
      "Processed: case_90.json\n",
      "Processed: case_91.json\n",
      "Processed: case_92.json\n",
      "Processed: case_93.json\n",
      "Processed: case_94.json\n",
      "Processed: case_96.json\n",
      "Processed: case_98.json\n",
      "Processed: case_99.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(\"/data/healthy-ml/scratch/abinitha/craft-md/craft-md/results/gpt4_1106/whitespace\")  # Replace with the actual folder path\n",
    "keys_to_remove = {\"evaluation_vignette_frq\", \"evaluation_multiturn_frq\", 'evaluation_singleturn_frq', 'evaluation_summarized_frq'}  # Replace with the keys you want to remove\n",
    "\n",
    "def remove_keys_from_dict(d, keys_to_remove):\n",
    "    \"\"\"Recursively remove specified keys from a nested dictionary.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        return {k: remove_keys_from_dict(v, keys_to_remove) for k, v in d.items() if k not in keys_to_remove}\n",
    "    elif isinstance(d, list):\n",
    "        return [remove_keys_from_dict(item, keys_to_remove) for item in d]\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "# Iterate over JSON files in the folder\n",
    "for file_path in sorted(folder_path.glob(\"*.json\")):\n",
    "    if file_path.stat().st_size == 0:  # Skip empty files\n",
    "        print(f\"Skipping empty file: {file_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)  # Load JSON file\n",
    "\n",
    "        # Remove specified keys\n",
    "        cleaned_data = remove_keys_from_dict(data, keys_to_remove)\n",
    "\n",
    "        # Save the cleaned JSON back to the file\n",
    "        with open(file_path, \"w\") as f:\n",
    "            json.dump(cleaned_data, f, indent=4)\n",
    "\n",
    "        print(f\"Processed: {file_path.name}\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping invalid JSON file: {file_path.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c269a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe903b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfc648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
