{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e27d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "\n",
    "from src.utils import call_gpt3_api, call_gpt4_api\n",
    "from src.mcq_frq import *\n",
    "from src.eval import eval_experiment\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9bad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI API credentials\n",
    "# Replace this information with your OpenAI key and organization ID.\n",
    "openai_key = open(\"../keys/openai_key.txt\", \"r\")\n",
    "openai.api_key = openai_key.readlines()[0].strip()\n",
    "\n",
    "organization_id = open(\"../keys/rajpurkarlab_org_id.txt\", \"r\")\n",
    "openai.organization = organization_id.readlines()[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf6ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "dataset = pd.read_csv(\"./data/dataset_final.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4fcfe8",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vignette_experiment(all_cases, case, case_idx, experiment_name, gpt_model_type, n_trials=10):\n",
    "    prompts = {'mcq_4': get_mcq_prompt, 'mcq_many': get_mcq_prompt, 'frq': get_frq_prompt}\n",
    "    \n",
    "    call_gpt_api = {\"gpt-3.5\": call_gpt3_api, \"gpt-4\": call_gpt4_api}\n",
    "    \n",
    "    if experiment_name == \"mcq_4\":\n",
    "        choices = get_choices(all_cases, case_idx)\n",
    "        prompt = prompts[experiment_name](case, choices)\n",
    "    elif experiment_name == \"mcq_many\":\n",
    "        choices = get_all_choices()\n",
    "        prompt = prompts[experiment_name](case, choices)\n",
    "    else:\n",
    "        prompt = prompts[experiment_name](case)\n",
    "        \n",
    "    input_msg = [{\"role\":\"system\", \"content\": prompt}]\n",
    "    \n",
    "    temp = []\n",
    "    for i in range(n_trials):\n",
    "        response = call_gpt_api[gpt_model_type](input_msg, n_responses=1)\n",
    "        temp.append(response)\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run MCQ-4, MCQ-many and FRQ for all case vignettes in the dataset.\n",
    "\n",
    "keys = [\"mcq_4\", \"mcq_many\", \"frq\"]\n",
    "res = {\"gpt-3.5\":{}, \"gpt-4\":{}}\n",
    "\n",
    "for case_idx, case_id in tqdm(dataset.case_id.items()):\n",
    "    res[\"gpt-3.5\"][case_id] = {key:{\"responses\":None} for key in keys}\n",
    "    res[\"gpt-4\"][case_id] = {key:{\"responses\":None} for key in keys}\n",
    "    case_desc = dataset.loc[case_idx, \"case_desc\"]\n",
    "    \n",
    "    for key in keys:\n",
    "        res[\"gpt-3.5\"][case_id][key][\"responses\"] = vignette_experiment(dataset, case_desc, case_idx, key, \"gpt-3.5\", n_trials=10)\n",
    "        res[\"gpt-4\"][case_id][key][\"responses\"] = vignette_experiment(dataset, case_desc, case_idx, key, \"gpt-4\", n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437a20f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run evaluation on all experiments (MCQ-4, MCQ-many, FRQ) in the dataset.\n",
    "\n",
    "evaluated_res = res.copy()\n",
    "for case in tqdm(dataset.case_id):\n",
    "    evaluated_res[\"gpt-3.5\"][case] = eval_experiment(res[\"gpt-3.5\"][case], \n",
    "                                                     case_id = case,\n",
    "                                                     exp_keys=[\"mcq_4\", \"mcq_many\", \"frq\"],\n",
    "                                                     method = \"autoeval\", \n",
    "                                                     full_dataset = dataset,\n",
    "                                                     n_trials=10)\n",
    "    evaluated_res[\"gpt-4\"][case] = eval_experiment(res[\"gpt-4\"][case],\n",
    "                                                   case_id = case,\n",
    "                                                   exp_keys=[\"mcq_4\", \"mcq_many\", \"frq\"],\n",
    "                                                   method = \"autoeval\",\n",
    "                                                   full_dataset = dataset,\n",
    "                                                   n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c3691",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(evaluated_res, open(\"./results/final_results_vignette.json\",\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ad063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
